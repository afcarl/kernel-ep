## Kernel EP 

### Observations

* Memory scales up only with D (#random features) not n in DefaultDynamicMatrix
which is good. Memory needed = D^2 which is still quite large.

### Implementation details

* The saved dataset should follow a uniform interface. 
One saved file should contain only one object. The object may contain a hierarchy
of datasets.

### To do 
* Comsider mex for DefaultDynamicMatrix.mmt(). This is the bottleneck.

* Test a learned operator with more test messages (2000 in Nicolas's paper). 
Plot the histogram of Hellinger distances to the ground truth.  Treat an
improper output message as having Hellinger=1 (maximum error).

* Compare a heat map of the ground truth (by importance sampling) output
message parameters (2d plot for mean and variance parameters for Gaussian) to
the heat map of the parameters of the messages from the learned operator using
the same set of incoming messages.

* Check importance sampling proposal. For each (m_in, m_out) where m_out is 
obtained by importance sampling, log(sum(W)) = log sum of all importance
weights indicates the reliability of m_out.

* Try product factor.

* Platform to test operators on multiple datasets. 
Given a new dataset, there should be a readily usable platform to run the whole 
process of training, testing and reporting the results.

### kernel part 

* In constructing random features, why can't we use L2 sequence representation
of the feature map and truncate it ? We get a finite-dimensional vector.
 

### EP part  

* When generating training messages for learning an operator, do we take into
account the fact that during test time certain messages are point mass (for
observed values) ? Specifically, do we generate messges with 0.01 variance
just like we do during test time to represent a point mass ?  

* How many draws do we need in importance sampling ?  

* In implementing an operator for a sigmoid factor, do we also have to
implement a new sigmoid factor ? If an existing sigmoid factor can be used, how
to select which SigmoidOp to use ?  

* Can the code for modeling be shared e.g., throwing ball model ?

